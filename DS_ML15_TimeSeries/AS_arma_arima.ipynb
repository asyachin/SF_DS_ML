{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile, io\n",
    "\n",
    "url = 'https://www.dropbox.com/s/g0l60pmw6xet2cu/train.zip?dl=1'\n",
    "\n",
    "request = requests.get(url, stream=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_filename = os.path.basename(url)[:-5]\n",
    "file_dir = './.temp/'\n",
    "with open(file_dir + zip_filename, 'wb') as zfile:\n",
    "    zfile.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(file_dir + zip_filename, \"r\") as z:\n",
    "    z.extractall(path= file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_dir + 'train.csv', sep=',', iterator=True, chunksize=20000000, low_memory = False)\n",
    "df = pd.concat(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8276222</th>\n",
       "      <td>8276222</td>\n",
       "      <td>2013-07-13</td>\n",
       "      <td>51</td>\n",
       "      <td>358519</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74058884</th>\n",
       "      <td>74058884</td>\n",
       "      <td>2016-03-22</td>\n",
       "      <td>18</td>\n",
       "      <td>1457417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111342427</th>\n",
       "      <td>111342427</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>2</td>\n",
       "      <td>409739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25818851</th>\n",
       "      <td>25818851</td>\n",
       "      <td>2014-06-23</td>\n",
       "      <td>2</td>\n",
       "      <td>1239815</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903001</th>\n",
       "      <td>3903001</td>\n",
       "      <td>2013-04-05</td>\n",
       "      <td>47</td>\n",
       "      <td>268664</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id        date  store_nbr  item_nbr  unit_sales onpromotion\n",
       "8276222      8276222  2013-07-13         51    358519         6.0         NaN\n",
       "74058884    74058884  2016-03-22         18   1457417         1.0       False\n",
       "111342427  111342427  2017-04-04          2    409739         1.0       False\n",
       "25818851    25818851  2014-06-23          2   1239815         5.0       False\n",
       "3903001      3903001  2013-04-05         47    268664        40.0         NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df[df.item_nbr==103501 ].groupby(\"date\")['unit_sales'].sum().reset_index()\n",
    "df.to_csv(file_dir + 'train_item_103501.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>unit_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>2017-08-12</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>2017-08-13</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1625 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  unit_sales\n",
       "0     2013-01-02       185.0\n",
       "1     2013-01-03       153.0\n",
       "2     2013-01-04       155.0\n",
       "3     2013-01-05       160.0\n",
       "4     2013-01-06       173.0\n",
       "...          ...         ...\n",
       "1620  2017-08-11        80.0\n",
       "1621  2017-08-12        84.0\n",
       "1622  2017-08-13       103.0\n",
       "1623  2017-08-14        88.0\n",
       "1624  2017-08-15        90.0\n",
       "\n",
       "[1625 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top1 = train[train.item_nbr == 265559 ]\n",
    "top1['date'] = pd.to_datetime(top1['date'])\n",
    "top1['year'] = top1['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "unit_sales_by_date = top1.groupby('date').sum()['unit_sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортируем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тест Адфуллера для проверки стационарных временных рядов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "X = unit_sales_by_date.values\n",
    "result = adfuller(X)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "if result[0] < result[4][\"5%\"]:\n",
    "    print (\"Reject Ho - Time Series is Stationary\")\n",
    "else:\n",
    "    print (\"Failed to Reject Ho - Time Series is Non-Stationary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель скользящего среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def moving_average_forecast(series, window_size):\n",
    "    forecast = []\n",
    "    for time in range(len(series) - window_size):\n",
    "        forecast.append(series[time:time + window_size].mean())\n",
    "    return np.array(forecast)\n",
    "moving_average_days = 6\n",
    "moving_avg = moving_average_forecast(unit_sales_by_date,moving_average_days )# \n",
    "\n",
    "print(moving_avg.shape,unit_sales_by_date.shape)\n",
    "\n",
    "print(\"mean_squared_error\",mean_squared_error(unit_sales_by_date.values[moving_average_days:], moving_avg))\n",
    "print(\"mean_absolute_error\",mean_absolute_error(unit_sales_by_date.values[moving_average_days:], moving_avg))\n",
    "print(\"mean_absolute_percentage_error\",mean_absolute_percentage_error(unit_sales_by_date.values[moving_average_days:], moving_avg))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "plt.plot(unit_sales_by_date.values[moving_average_days:], label=\"Actual\")\n",
    "plt.plot(moving_avg, label=\"Moving average\")\n",
    "plt.ylabel(\"Total Unit Sold\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.title(\"Moving Average Forecast\")\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train = unit_sales_by_date['2013':'2016'].values\n",
    "x_test  = unit_sales_by_date['2017'].values\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df[\"Original Values\"]  = unit_sales_by_date\n",
    "df[\"shift1\"] = df[\"Original Values\"].shift()\n",
    "df[\"shift2\"] = df[\"shift1\"].shift()\n",
    "df[\"shift3\"] = df[\"shift2\"].shift()\n",
    "df[\"shift4\"] = df[\"shift3\"].shift()\n",
    "df[\"shift5\"] = df[\"shift4\"].shift()\n",
    "df[\"shift6\"] = df[\"shift5\"].shift()\n",
    "\n",
    "\n",
    "lag_value = 6\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "x_train, y_train = df['2013':'2016'].iloc[:,0:lag_value].values, df['2013':'2016'].iloc[:,lag_value:].values\n",
    "x_test, y_test = df['2017'].iloc[:,0:lag_value].values, df['2017'].iloc[:,lag_value:].values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "\n",
    "\n",
    "ar_predictions = reg.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(ar_predictions ,label = \"Predictions\")\n",
    "plt.plot(y_test, label = \"Original\" )\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Sale Count\")\n",
    "\n",
    "print(\"mean_squared_error\",mean_squared_error(y_test, ar_predictions))\n",
    "print(\"mean_absolute_error\",mean_absolute_error(y_test, ar_predictions))\n",
    "print(\"mean_absolute_percentage_error\",mean_absolute_percentage_error(y_test, ar_predictions))\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, чтобы построить модель нам нужно знать ее порядок, состоящий из 3-х параметров:\n",
    "    \n",
    "    p — порядок компоненты AR\n",
    "    d — порядок интегрированного ряда\n",
    "    q — порядок компонетны MA\n",
    "    \n",
    "d мы уже знаем - это 1\n",
    "\n",
    "осталось определить p и q. Для их определения нам надо изучить авторкорреляционную(ACF) и частично автокорреляционную(PACF) функции для ряда первых разностей.\n",
    "\n",
    "ACF поможет нам определить q, т. к. по ее коррелограмме можно определить количество автокорреляционных коэффициентов сильно отличных от 0 в модели MA\n",
    "PACF поможет нам определить p, т. к. по ее коррелограмме можно определить максимальный номер коэффициента сильно отличный от 0 в модели AR.\n",
    "\n",
    "Чтобы построить соответствующие коррелограммы, в пакете statsmodels имеются следующие функции: plot_acf() и plot_pacf(). Они выводят графики ACF и PACF, у которых по оси X откладываются номера лагов, а по оси Y значения соответствующих функций. Нужно отметить, что количество лагов в функциях и определяет число значимых коэффициентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(unit_sales_by_date.values.squeeze(), lags=6, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(unit_sales_by_date, lags=6, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После изучения коррелограммы PACF можно сделать вывод, что p = 6, т.к. на ней все лаги сильно отличны от нуля.\n",
    "По коррелограмме ACF можно предположить, что q = 6, т.к. на лаг 6 значении функций резко возрастает. Итак, когда известны все параметры можно построить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "x_train, y_train = df['2013':'2016'].iloc[:,0:lag_value], df['2013':'2016'].iloc[:,lag_value:]\n",
    "x_test, y_test = df['2017'].iloc[:,0:lag_value], df['2017'].iloc[:,lag_value:]\n",
    "\n",
    "ARMA_model = ARMA(x_train.values.reshape(-1).tolist(), (6,6)).fit()\n",
    "arma_predictions = ARMA_model.predict(start=len(x_train), end=len(x_train) + len(x_test)-1, dynamic=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(arma_predictions ,label = \"Predictions\")\n",
    "plt.plot(y_test.values, label = \"Original\" )\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Sale Count\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "print(\"mean_squared_error\",mean_squared_error(y_test, arma_predictions))\n",
    "print(\"mean_absolute_error\",mean_absolute_error(y_test, arma_predictions))\n",
    "print(\"mean_absolute_percentage_error\",mean_absolute_percentage_error(y_test, arma_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "model = ARIMA(x_train['Original Values'].values, (6,1,6)).fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17,7))\n",
    "shown_train_size = 150\n",
    "train_size = len(x_train['Original Values'].values)\n",
    "test_size = len(x_test['Original Values'].values) \n",
    "ax = x_test.set_index(pd.Series(range(shown_train_size, shown_train_size + test_size)))['Original Values'].plot(ax=ax)\n",
    "model.plot_predict(start=train_size-shown_train_size,end=train_size+test_size -1,dynamic=False, plot_insample=True,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "arima_predictions = model.predict(train_size, train_size + test_size -1)\n",
    "print(\"mean_squared_error\",mean_squared_error(y_test, arima_predictions))\n",
    "print(\"mean_absolute_error\",mean_absolute_error(y_test, arima_predictions))\n",
    "print(\"mean_absolute_percentage_error\",mean_absolute_percentage_error(y_test, arima_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}