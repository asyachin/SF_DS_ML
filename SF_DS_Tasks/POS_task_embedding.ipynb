{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"POS_task_embedding.ipynb","provenance":[{"file_id":"1H143EMQrifO-I8lL6JdKiArOmEVGb7os","timestamp":1633855127233}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hsP7cV1_arhs"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torchtext import datasets\n","\n","import numpy as np\n","from sklearn.metrics import classification_report\n","\n","import random\n","\n","from gensim.models import FastText\n","from nltk.stem import PorterStemmer\n","from sklearn.metrics import accuracy_score, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sNRfW260a3jg"},"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyk3BCHza5ru"},"source":["train_data, _, test_data = datasets.UDPOS()\n","train_data = [d for d in train_data]\n","test_data = [d for d in test_data]\n","\n","train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n","train_tags = [ d[1] for d in train_data]\n","\n","test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n","test_tags = [d[1] for d in test_data]\n","\n","tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBDDAUdhbxCq"},"source":["stemmer = PorterStemmer()\n","\n","word_to_ix = {}\n","for tokens in train_tokens:\n","    for word in tokens:\n","        word = stemmer.stem(word)\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","\n","word_to_ix[\"UNK\"] =  len(word_to_ix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0hkWDYVab5PT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633856507496,"user_tz":-120,"elapsed":4252,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"6618e461-517f-43a0-b2f6-7cfcb5377a9d"},"source":["max_len = 20\n","pad_inds = len(tag2num)\n","\n","def prepare_sequence(seq, to_ix):\n","    stemmer = PorterStemmer()\n","    stemmed_words = [stemmer.stem(w) for w in seq]\n","    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n","    return torch.tensor(idxs, dtype=torch.long)\n","\n","\n","def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n","    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n","    \n","    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n","    all_tags = [tags[:max_len] for tags in all_tags]\n","    \n","    all_ids = []\n","    for tokens in all_tokens:\n","        ids = prepare_sequence(tokens, word_to_ix)\n","        all_ids.append(ids)\n","        \n","    X_vecs = []\n","    Y_vecs = []\n","\n","    for ids, tags in zip(all_ids, all_tags):\n","        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n","        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n","        \n","    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n","    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n","\n","    # в качестве заполнителя Y используем pad_tags\n","    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n","    \n","    return X, Y\n","\n","X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n","\n","X_train.size(), Y_train.size()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([12543, 20]), torch.Size([12543, 20]))"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"GYNHAQxZcHhS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633856508202,"user_tz":-120,"elapsed":721,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"bd66099d-f46a-4bd1-8522-f378a0464f0d"},"source":["X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n","\n","X_test.size(), Y_test.size()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([2077, 20]), torch.Size([2077, 20]))"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"UeBb8AbNcdX_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633856508203,"user_tz":-120,"elapsed":8,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"1c03641e-b454-46cf-afe2-2ada65edffec"},"source":["print(X_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    0,     1,     2,  ...,    14,    15,    11],\n","        [   23,    24,     6,  ...,    37, 12121, 12121],\n","        [   38,     3,    39,  ..., 12121, 12121, 12121],\n","        ...,\n","        [ 3083,    43,    28,  ...,   211,    29,    25],\n","        [   11,  4206,    13,  ...,    17,   368,    42],\n","        [  112,    28,   387,  ...,   132,    43,  1054]])\n"]}]},{"cell_type":"code","metadata":{"id":"GfjixGEdceuN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633856508203,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"f0063226-7e40-4437-e2c2-629823a55fba"},"source":["print(Y_train)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[11, 12, 11,  ...,  7,  1,  5],\n","        [12,  5,  7,  ..., 12, 17, 17],\n","        [11, 12,  0,  ..., 17, 17, 17],\n","        ...,\n","        [ 2, 10,  3,  ...,  2,  3,  5],\n","        [ 5,  7,  1,  ...,  1,  7, 10],\n","        [10,  3,  2,  ...,  7, 10,  2]])\n"]}]},{"cell_type":"code","metadata":{"id":"W8RSqbmOckWA"},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","bs = 128\n","data = TensorDataset(X_train, Y_train)\n","dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5lgGR7Dcl0X"},"source":["class BiLSTMPOSTagger(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n","        \n","        super().__init__()\n","        \n","        # padding_idx=pad_idx - это номер id \"заполнителя\". \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n","        \n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n","        \n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    '''def forward(self, text):\n","        raise NotImplementedException()       \n","        return predictions '''\n","        \n","    def forward(self, text):\n","      outputs, (hidden, cell) = self.lstm(self.embedding(text))\n","      predictions = self.fc(self.dropout(outputs))\n","      return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHtLZSe8dBWV"},"source":["def train_on_epoch(model, dataloader, optimizer):\n","    model.train()\n","    for batch in dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input, b_tags = batch\n","        \n","        model.zero_grad()\n","        outputs = model(b_input)  \n","\n","        # outputs = [batch size, sent len, out dim]\n","        outputs = outputs.view(-1, outputs.shape[-1])       \n","        # outputs = [batch size * sent len, out dim]\n","\n","        # b_tags = [batch size, sent len]\n","        b_tags = b_tags.view(-1)\n","        # b_tags = [batch size * sent len]\n","        \n","        loss = criterion(outputs, b_tags)\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","def predict_on_dataloader(model, dataloaded):\n","    model.eval()\n","        \n","    all_outputs = []\n","    all_tags = []\n","    for batch in dataloaded:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input, b_tags = batch\n","        outputs = model(b_input)  \n","        \n","        outputs = outputs.view(-1, outputs.shape[-1])       \n","        b_tags = b_tags.view(-1)\n","\n","        all_outputs.append(outputs)\n","        all_tags.append(b_tags)\n","\n","    all_outputs = torch.cat(all_outputs)\n","    all_tags = torch.cat(all_tags)\n","    \n","    return all_outputs, all_tags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9HPx3ywdDUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633856508489,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"2685ba21-a74d-4309-cae2-07b2a3fbd39b"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"8uDf2IvsdEeg"},"source":["INPUT_DIM = len(word_to_ix)+1\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 128\n","OUTPUT_DIM = len(tag2num)\n","N_LAYERS = 2\n","BIDIRECTIONAL = True\n","DROPOUT = 0.25\n","PAD_IDX = len(word_to_ix)\n","\n","model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n","optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWu61Ea-dKbc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633857005232,"user_tz":-120,"elapsed":496746,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"f6bac9b6-1b37-4a77-b13c-330bc05dd728"},"source":["epochs = 50\n","for e in range(epochs):\n","    train_on_epoch(model, dataloader, optimizer)    \n","    \n","    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n","    loss = criterion(all_outputs, all_tags).item()\n","    all_outputs = all_outputs.detach().cpu().numpy()\n","    all_tags = all_tags.detach().cpu().numpy()\n","    \n","    mask = all_tags != pad_inds\n","    loss = loss/len(all_tags[mask]) \n","    all_tags = all_tags[mask]\n","    all_preds = np.argmax(all_outputs, axis=1)[mask]\n","    \n","    print(f\"{e}:\\tLoss {loss}, \"\n","          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n","          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tLoss 6.741235945906115e-06, accuracy: 0.6461435327835077, f1-macro: 0.48546129403440486\n","1:\tLoss 4.921648157281714e-06, accuracy: 0.7301118716827494, f1-macro: 0.6299827720070516\n","2:\tLoss 4.01134013592967e-06, accuracy: 0.7758630233030129, f1-macro: 0.6871211251319709\n","3:\tLoss 3.442711597493467e-06, accuracy: 0.8071612637379534, f1-macro: 0.7309531016792299\n","4:\tLoss 3.0369856321253815e-06, accuracy: 0.8297816072867273, f1-macro: 0.7580946192745808\n","5:\tLoss 2.7246080912696876e-06, accuracy: 0.8463747793624729, f1-macro: 0.7740945761953705\n","6:\tLoss 2.47094569125913e-06, accuracy: 0.8595546043284932, f1-macro: 0.7912657692721271\n","7:\tLoss 2.2645470541727387e-06, accuracy: 0.8710123803022196, f1-macro: 0.8063073963332774\n","8:\tLoss 2.075551021694195e-06, accuracy: 0.8808342097332669, f1-macro: 0.8216639154487693\n","9:\tLoss 1.9191753876238804e-06, accuracy: 0.8890385431465525, f1-macro: 0.8349033401922592\n","10:\tLoss 1.776289310684185e-06, accuracy: 0.8969661186860766, f1-macro: 0.8473846790002871\n","11:\tLoss 1.6322475934641986e-06, accuracy: 0.9047399398512888, f1-macro: 0.8596390561494269\n","12:\tLoss 1.5051908557325285e-06, accuracy: 0.9121570508680972, f1-macro: 0.8724460893989231\n","13:\tLoss 1.3864317251870437e-06, accuracy: 0.9190329464873276, f1-macro: 0.8809110982764063\n","14:\tLoss 1.2661025368079395e-06, accuracy: 0.9259518933313653, f1-macro: 0.8920900735617102\n","15:\tLoss 1.1493848846830537e-06, accuracy: 0.9330307447246874, f1-macro: 0.9003517817279365\n","16:\tLoss 1.0506822990211445e-06, accuracy: 0.9389595133981562, f1-macro: 0.9125793044495527\n","17:\tLoss 9.524040285454167e-07, accuracy: 0.9443163157991845, f1-macro: 0.9202947397918116\n","18:\tLoss 8.450150786736114e-07, accuracy: 0.9518318296155526, f1-macro: 0.9311820264602736\n","19:\tLoss 7.737291193029245e-07, accuracy: 0.9557679415979384, f1-macro: 0.9381499809881712\n","20:\tLoss 7.098027372937664e-07, accuracy: 0.9595872002558473, f1-macro: 0.9429355436083052\n","21:\tLoss 6.316237639768525e-07, accuracy: 0.9646610946081416, f1-macro: 0.9496252414507746\n","22:\tLoss 5.894971474374359e-07, accuracy: 0.9664077443003254, f1-macro: 0.9545922763882179\n","23:\tLoss 5.249484517626702e-07, accuracy: 0.9701716513834818, f1-macro: 0.9601616796283212\n","24:\tLoss 4.5646466804862926e-07, accuracy: 0.9746489787634458, f1-macro: 0.9653619692079057\n","25:\tLoss 3.965569540895018e-07, accuracy: 0.9782406809473729, f1-macro: 0.9700511087472338\n","26:\tLoss 3.881053837256094e-07, accuracy: 0.978511288646162, f1-macro: 0.9708606211012619\n","27:\tLoss 3.1664523059895386e-07, accuracy: 0.9826319058777222, f1-macro: 0.9753884944677185\n","28:\tLoss 2.4933754685533644e-07, accuracy: 0.9874536430561449, f1-macro: 0.9821972346902252\n","29:\tLoss 2.2762479807442432e-07, accuracy: 0.9884807222765488, f1-macro: 0.9828481170089293\n","30:\tLoss 2.1368854152777017e-07, accuracy: 0.9889542857494296, f1-macro: 0.9843087432509663\n","31:\tLoss 1.8199016947996636e-07, accuracy: 0.9905840821171362, f1-macro: 0.9869368271072538\n","32:\tLoss 1.9092065238903956e-07, accuracy: 0.9896431053463471, f1-macro: 0.98700511588937\n","33:\tLoss 1.884026670979114e-07, accuracy: 0.9895262520218701, f1-macro: 0.9868199611499007\n","34:\tLoss 1.6403933453018952e-07, accuracy: 0.9907132357915582, f1-macro: 0.9877554024619537\n","35:\tLoss 1.3090260960814883e-07, accuracy: 0.9928227458071183, f1-macro: 0.9899375845709225\n","36:\tLoss 9.286691727526482e-08, accuracy: 0.9956887273442929, f1-macro: 0.9944751648729637\n","37:\tLoss 8.09031936592521e-08, accuracy: 0.9962483932667885, f1-macro: 0.9953806466152384\n","38:\tLoss 7.578922766811044e-08, accuracy: 0.9965497518404398, f1-macro: 0.9955612547497457\n","39:\tLoss 8.424712724745554e-08, accuracy: 0.995676426994348, f1-macro: 0.9941088179279188\n","40:\tLoss 9.340425907549731e-08, accuracy: 0.9950429589721828, f1-macro: 0.9929866456824719\n","41:\tLoss 6.556266462925984e-08, accuracy: 0.9967650079644765, f1-macro: 0.9955354312063477\n","42:\tLoss 3.846495060769479e-08, accuracy: 0.998597760106275, f1-macro: 0.9980647096624565\n","43:\tLoss 2.9298264814607795e-08, accuracy: 0.9988991186799264, f1-macro: 0.9985288199108296\n","44:\tLoss 2.43628886634707e-08, accuracy: 0.9992004772535779, f1-macro: 0.9991455142017135\n","45:\tLoss 2.2109493217246145e-08, accuracy: 0.9992619790033026, f1-macro: 0.9992147681324594\n","46:\tLoss 2.093694877667988e-08, accuracy: 0.9992742793532476, f1-macro: 0.9989719964798847\n","47:\tLoss 2.080171692642417e-08, accuracy: 0.9992435284783852, f1-macro: 0.9990398920941026\n","48:\tLoss 1.863593099599653e-08, accuracy: 0.9993972828526971, f1-macro: 0.9992322026038621\n","49:\tLoss 1.702386979656913e-08, accuracy: 0.9993972828526971, f1-macro: 0.9992858435912401\n"]}]},{"cell_type":"code","metadata":{"id":"8kcXubKVdVov"},"source":["def count_metrics(model, dataloader):\n","  y_pred, y_true = predict_on_dataloader(model, dataloader)\n","\n","  y_pred = y_pred.detach().cpu().numpy()\n","  y_true = y_true.detach().cpu().numpy()\n","\n","  mask = y_true != pad_inds\n","  y_true = y_true[mask]\n","  y_pred = np.argmax(y_pred, axis=1)[mask]\n","\n","  print(classification_report(y_true, y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"25kR8EZsdavw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633857007497,"user_tz":-120,"elapsed":2275,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"20d51e78-c36f-4d6b-d2da-2a41814acb6a"},"source":["count_metrics(model, dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9962\n","           1       1.00      1.00      1.00     13578\n","           2       1.00      1.00      1.00      8547\n","           3       1.00      1.00      1.00     10404\n","           4       1.00      1.00      1.00      5202\n","           5       1.00      1.00      1.00     13014\n","           6       1.00      1.00      1.00       649\n","           7       1.00      1.00      1.00     27080\n","           8       1.00      1.00      1.00      3339\n","           9       1.00      1.00      1.00      4484\n","          10       1.00      1.00      1.00     15619\n","          11       1.00      1.00      1.00     10523\n","          12       1.00      1.00      1.00     16990\n","          13       1.00      0.99      1.00      3134\n","          14       1.00      1.00      1.00       484\n","          15       1.00      1.00      1.00     18849\n","          16       1.00      1.00      1.00       739\n","\n","    accuracy                           1.00    162597\n","   macro avg       1.00      1.00      1.00    162597\n","weighted avg       1.00      1.00      1.00    162597\n","\n"]}]},{"cell_type":"code","metadata":{"id":"VAOUiigWdY7m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633857007771,"user_tz":-120,"elapsed":276,"user":{"displayName":"Alexander Syachin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvlbMmxJYfSnvsQAt3q6KKUtvKCF8z9pJSzBBSi5A=s64","userId":"01407196237518825368"}},"outputId":"335bad3d-3d4d-4e07-d4c6-2707cc02f38c"},"source":["data = TensorDataset(X_test, Y_test)\n","test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n","count_metrics(model, test_dataloader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.64      0.76      0.69      1466\n","           1       0.86      0.82      0.84      1656\n","           2       0.74      0.77      0.76      1066\n","           3       0.84      0.91      0.87      1336\n","           4       0.99      0.99      0.99       599\n","           5       0.95      0.96      0.95      1607\n","           6       0.81      0.65      0.72       115\n","           7       0.76      0.76      0.76      3446\n","           8       0.89      0.54      0.68       448\n","           9       0.72      0.83      0.77       546\n","          10       0.94      0.95      0.94      1923\n","          11       0.63      0.64      0.64      1773\n","          12       0.99      0.99      0.99      2467\n","          13       0.55      0.52      0.54       330\n","          14       0.96      0.68      0.80        81\n","          15       0.77      0.73      0.75      2306\n","          16       0.18      0.03      0.05       114\n","\n","    accuracy                           0.81     21279\n","   macro avg       0.78      0.74      0.75     21279\n","weighted avg       0.81      0.81      0.81     21279\n","\n"]}]},{"cell_type":"code","metadata":{"id":"W32kZg1qdbSj"},"source":[""],"execution_count":null,"outputs":[]}]}